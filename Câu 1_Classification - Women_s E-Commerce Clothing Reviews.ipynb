{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Câu 1_Classification - Women's E-Commerce Clothing Reviews.ipynb","provenance":[{"file_id":"145EFT5ey3fuT6V4l8qq0zuo7tPuB9gTR","timestamp":1633751462806}],"collapsed_sections":[],"authorship_tag":"ABX9TyMwTWD+WjOefi+7EZK057hD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"LcrEOquYFXCx"},"source":["#Câu 1: Classification - Women's E-Commerce Clothing Reviews (1.0 điểm)\n","Use **womens-ecommerce-clothing-reviews** dataset (file \n","Womens_Clothing_E_Commerce_Reviews.xlsx, sheetName: **Reviews**) to build a \n","model to predict products’ ratings (based on **Review Text** and other optional \n","features)\n","<br>Please predict ratings for products in Womens_Clothing_E_Commerce_Reviews.xlsx, \n","<br>sheetName: **new_reviews**.\n","<br>Read more information here:\n","https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fMwl0K2oFWCU","cellView":"form","executionInfo":{"status":"ok","timestamp":1633831050079,"user_tz":-420,"elapsed":57775,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"94f6fd2a-4a86-4bba-8e32-06d029af0fff"},"source":["#@title Install Pakages\n","!apt update\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q http://archive.apache.org/dist/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz\n","!tar -xvf spark-2.4.0-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.0-bin-hadoop2.7\"\n","import findspark  # Tìm Spark\n","findspark.init()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Get:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:13 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,431 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Get:15 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,210 kB]\n","Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,365 kB]\n","Hit:18 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,802 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,801 kB]\n","Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [922 kB]\n","Get:22 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [40.8 kB]\n","Fetched 11.9 MB in 7s (1,607 kB/s)\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","39 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","spark-2.4.0-bin-hadoop2.7/\n","spark-2.4.0-bin-hadoop2.7/python/\n","spark-2.4.0-bin-hadoop2.7/python/setup.cfg\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/resultiterable.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/python/\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/python/pyspark/\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/python/pyspark/shell.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/heapq3.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/join.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/version.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/rdd.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/java_gateway.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/find_spark_home.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/_globals.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/worker.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/feature.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/random.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/recommendation.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/fpm.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/stat/\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/stat/KernelDensity.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/stat/distribution.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/stat/test.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/stat/_statistics.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/stat/__init__.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/util.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/regression.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/clustering.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/linalg/\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/linalg/distributed.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/linalg/__init__.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/tree.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/__init__.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/evaluation.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/tests.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/util.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/test_broadcast.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/shell.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/feature.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/recommendation.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/fpm.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/classification.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/stat.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/util.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/tuning.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/regression.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/base.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/clustering.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/wrapper.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/pipeline.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/linalg/\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/linalg/__init__.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/param/\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/param/_shared_params_code_gen.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/param/shared.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/param/__init__.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/__init__.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/evaluation.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/common.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/tests.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/image.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/test_serializers.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/cloudpickle.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/daemon.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/files.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/rddsampler.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/statcounter.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/kafka.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/util.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/kinesis.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/flume.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/__init__.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/context.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/tests.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/dstream.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/listener.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/taskcontext.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/__init__.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/storagelevel.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/broadcast.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/profiler.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/traceback_utils.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/context.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/status.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/streaming.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/readwriter.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/catalog.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/session.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/column.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/functions.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/dataframe.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/window.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/udf.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/__init__.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/utils.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/group.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/context.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/tests.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/conf.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/types.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/tests.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/conf.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/shuffle.py\n","spark-2.4.0-bin-hadoop2.7/python/.gitignore\n","spark-2.4.0-bin-hadoop2.7/python/docs/\n","spark-2.4.0-bin-hadoop2.7/python/docs/epytext.py\n","spark-2.4.0-bin-hadoop2.7/python/docs/make2.bat\n","spark-2.4.0-bin-hadoop2.7/python/docs/pyspark.sql.rst\n","spark-2.4.0-bin-hadoop2.7/python/docs/make.bat\n","spark-2.4.0-bin-hadoop2.7/python/docs/index.rst\n","spark-2.4.0-bin-hadoop2.7/python/docs/_templates/\n","spark-2.4.0-bin-hadoop2.7/python/docs/_templates/layout.html\n","spark-2.4.0-bin-hadoop2.7/python/docs/_static/\n","spark-2.4.0-bin-hadoop2.7/python/docs/_static/pyspark.js\n","spark-2.4.0-bin-hadoop2.7/python/docs/_static/pyspark.css\n","spark-2.4.0-bin-hadoop2.7/python/docs/pyspark.ml.rst\n","spark-2.4.0-bin-hadoop2.7/python/docs/pyspark.streaming.rst\n","spark-2.4.0-bin-hadoop2.7/python/docs/conf.py\n","spark-2.4.0-bin-hadoop2.7/python/docs/pyspark.mllib.rst\n","spark-2.4.0-bin-hadoop2.7/python/docs/pyspark.rst\n","spark-2.4.0-bin-hadoop2.7/python/docs/Makefile\n","spark-2.4.0-bin-hadoop2.7/python/test_coverage/\n","spark-2.4.0-bin-hadoop2.7/python/test_coverage/conf/\n","spark-2.4.0-bin-hadoop2.7/python/test_coverage/conf/spark-defaults.conf\n","spark-2.4.0-bin-hadoop2.7/python/test_coverage/sitecustomize.py\n","spark-2.4.0-bin-hadoop2.7/python/test_coverage/coverage_daemon.py\n","spark-2.4.0-bin-hadoop2.7/python/run-tests-with-coverage\n","spark-2.4.0-bin-hadoop2.7/python/pyspark.egg-info/\n","spark-2.4.0-bin-hadoop2.7/python/pyspark.egg-info/top_level.txt\n","spark-2.4.0-bin-hadoop2.7/python/pyspark.egg-info/dependency_links.txt\n","spark-2.4.0-bin-hadoop2.7/python/pyspark.egg-info/requires.txt\n","spark-2.4.0-bin-hadoop2.7/python/pyspark.egg-info/PKG-INFO\n","spark-2.4.0-bin-hadoop2.7/python/pyspark.egg-info/SOURCES.txt\n","spark-2.4.0-bin-hadoop2.7/python/MANIFEST.in\n","spark-2.4.0-bin-hadoop2.7/python/test_support/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/userlibrary.py\n","spark-2.4.0-bin-hadoop2.7/python/test_support/userlib-0.1.zip\n","spark-2.4.0-bin-hadoop2.7/python/test_support/SimpleHTTPServer.py\n","spark-2.4.0-bin-hadoop2.7/python/test_support/hello/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/hello/sub_hello/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/hello/sub_hello/sub_hello.txt\n","spark-2.4.0-bin-hadoop2.7/python/test_support/hello/hello.txt\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/people_array.json\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/text-test.txt\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/ages_newlines.csv\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/people.json\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/part-r-00008.gz.parquet\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/.part-r-00008.gz.parquet.crc\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/part-r-00005.gz.parquet\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/.part-r-00005.gz.parquet.crc\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00002.gz.parquet.crc\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00002.gz.parquet\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00004.gz.parquet\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00004.gz.parquet.crc\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/.part-r-00007.gz.parquet.crc\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/part-r-00007.gz.parquet\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_common_metadata\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_metadata\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_SUCCESS\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/streaming/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/streaming/text-test.txt\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/ages.csv\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/people1.json\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/_SUCCESS\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/people_array_utf16le.json\n","spark-2.4.0-bin-hadoop2.7/python/run-tests.py\n","spark-2.4.0-bin-hadoop2.7/python/run-tests\n","spark-2.4.0-bin-hadoop2.7/python/.coveragerc\n","spark-2.4.0-bin-hadoop2.7/python/lib/\n","spark-2.4.0-bin-hadoop2.7/python/lib/pyspark.zip\n","spark-2.4.0-bin-hadoop2.7/python/lib/PY4J_LICENSE.txt\n","spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip\n","spark-2.4.0-bin-hadoop2.7/python/setup.py\n","spark-2.4.0-bin-hadoop2.7/python/README.md\n","spark-2.4.0-bin-hadoop2.7/python/dist/\n","spark-2.4.0-bin-hadoop2.7/python/pylintrc\n","spark-2.4.0-bin-hadoop2.7/conf/\n","spark-2.4.0-bin-hadoop2.7/conf/fairscheduler.xml.template\n","spark-2.4.0-bin-hadoop2.7/conf/spark-defaults.conf.template\n","spark-2.4.0-bin-hadoop2.7/conf/docker.properties.template\n","spark-2.4.0-bin-hadoop2.7/conf/log4j.properties.template\n","spark-2.4.0-bin-hadoop2.7/conf/metrics.properties.template\n","spark-2.4.0-bin-hadoop2.7/conf/slaves.template\n","spark-2.4.0-bin-hadoop2.7/conf/spark-env.sh.template\n","spark-2.4.0-bin-hadoop2.7/licenses/\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-heapq.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-paranamer.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-graphlib-dot.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-minlog.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-slf4j.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-jquery.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-scopt.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-vis.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-sbt-launch-lib.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-spire.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-matchMedia-polyfill.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-kryo.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-arpack.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-scala.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-javassist.html\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-json-formatter.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-jodd.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-automaton.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-janino.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-dagre-d3.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-sorttable.js.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-py4j.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-d3.min.js.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-respond.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-CC0.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-zstd.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-cloudpickle.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-pmml-model.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-pyrolite.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-netlib.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-AnchorJS.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-modernizr.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-machinist.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-javolution.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-xmlenc.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-join.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-jline.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-antlr.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-jtransforms.html\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-leveldbjni.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-protobuf.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-bootstrap.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-zstd-jni.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-datatables.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-f2j.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-reflectasm.txt\n","spark-2.4.0-bin-hadoop2.7/sbin/\n","spark-2.4.0-bin-hadoop2.7/sbin/start-slave.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/stop-history-server.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/stop-slave.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/stop-mesos-dispatcher.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/start-all.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/spark-daemon.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/start-master.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/spark-daemons.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/spark-config.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/start-slaves.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/start-mesos-shuffle-service.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/start-history-server.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/start-shuffle-service.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/slaves.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/stop-slaves.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/stop-thriftserver.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/stop-master.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/stop-shuffle-service.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/start-mesos-dispatcher.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/stop-mesos-shuffle-service.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/start-thriftserver.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/stop-all.sh\n","spark-2.4.0-bin-hadoop2.7/kubernetes/\n","spark-2.4.0-bin-hadoop2.7/kubernetes/tests/\n","spark-2.4.0-bin-hadoop2.7/kubernetes/tests/pyfiles.py\n","spark-2.4.0-bin-hadoop2.7/kubernetes/tests/worker_memory_check.py\n","spark-2.4.0-bin-hadoop2.7/kubernetes/tests/py_container_checks.py\n","spark-2.4.0-bin-hadoop2.7/kubernetes/dockerfiles/\n","spark-2.4.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/\n","spark-2.4.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/Dockerfile\n","spark-2.4.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/\n","spark-2.4.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/python/\n","spark-2.4.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n","spark-2.4.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/R/\n","spark-2.4.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n","spark-2.4.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/entrypoint.sh\n","spark-2.4.0-bin-hadoop2.7/jars/\n","spark-2.4.0-bin-hadoop2.7/jars/commons-lang3-3.5.jar\n","spark-2.4.0-bin-hadoop2.7/jars/arrow-format-0.10.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-yarn-common-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-jobclient-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/json4s-jackson_2.11-3.5.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jersey-container-servlet-2.22.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/curator-framework-2.7.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/parquet-column-1.10.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/pyrolite-4.13.jar\n","spark-2.4.0-bin-hadoop2.7/jars/bonecp-0.8.0.RELEASE.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hppc-0.7.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/metrics-jvm-3.1.5.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jersey-guava-2.22.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/guice-3.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/super-csv-2.2.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jsp-api-2.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-net-3.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/validation-api-1.1.0.Final.jar\n","spark-2.4.0-bin-hadoop2.7/jars/json4s-ast_2.11-3.5.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/javax.inject-1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-shuffle-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/avro-ipc-1.8.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-network-shuffle_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/orc-shims-1.5.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jersey-container-servlet-core-2.22.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/zjsonpatch-0.3.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/scala-compiler-2.11.12.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-graphx_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/curator-client-2.7.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jersey-media-jaxb-2.22.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/avro-mapred-1.8.2-hadoop2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/antlr4-runtime-4.7.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-kubernetes_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jackson-module-jaxb-annotations-2.6.7.jar\n","spark-2.4.0-bin-hadoop2.7/jars/okhttp-3.8.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/leveldbjni-all-1.8.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-tags_2.11-2.4.0-tests.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jackson-mapper-asl-1.9.13.jar\n","spark-2.4.0-bin-hadoop2.7/jars/ST4-4.0.4.jar\n","spark-2.4.0-bin-hadoop2.7/jars/eigenbase-properties-1.1.5.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jackson-jaxrs-1.9.13.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-beanutils-1.7.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jackson-annotations-2.6.7.jar\n","spark-2.4.0-bin-hadoop2.7/jars/kubernetes-model-2.0.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-tags_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jackson-module-paranamer-2.7.9.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jdo-api-3.0.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jersey-server-2.22.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/scala-parser-combinators_2.11-1.1.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/snappy-java-1.1.7.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/arrow-memory-0.10.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hk2-utils-2.4.0-b34.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-repl_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/joda-time-2.9.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-crypto-1.0.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/aopalliance-1.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/log4j-1.2.17.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-pool-1.5.4.jar\n","spark-2.4.0-bin-hadoop2.7/jars/xz-1.5.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hk2-locator-2.4.0-b34.jar\n","spark-2.4.0-bin-hadoop2.7/jars/libthrift-0.9.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/chill-java-0.9.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/logging-interceptor-3.8.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/opencsv-2.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/lz4-java-1.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-streaming_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/slf4j-log4j12-1.7.16.jar\n","spark-2.4.0-bin-hadoop2.7/jars/calcite-core-1.2.0-incubating.jar\n","spark-2.4.0-bin-hadoop2.7/jars/breeze_2.11-0.13.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/parquet-hadoop-bundle-1.6.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-hive-thriftserver_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/javax.inject-2.4.0-b34.jar\n","spark-2.4.0-bin-hadoop2.7/jars/metrics-json-3.1.5.jar\n","spark-2.4.0-bin-hadoop2.7/jars/aopalliance-repackaged-2.4.0-b34.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-mesos_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jcl-over-slf4j-1.7.16.jar\n","spark-2.4.0-bin-hadoop2.7/jars/antlr-runtime-3.4.jar\n","spark-2.4.0-bin-hadoop2.7/jars/httpcore-4.4.10.jar\n","spark-2.4.0-bin-hadoop2.7/jars/metrics-graphite-3.1.5.jar\n","spark-2.4.0-bin-hadoop2.7/jars/netty-3.9.9.Final.jar\n","spark-2.4.0-bin-hadoop2.7/jars/guava-14.0.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jaxb-api-2.2.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/datanucleus-core-3.2.10.jar\n","spark-2.4.0-bin-hadoop2.7/jars/compress-lzf-1.0.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/antlr-2.7.7.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jersey-common-2.22.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-yarn-client-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-lang-2.6.jar\n","spark-2.4.0-bin-hadoop2.7/jars/datanucleus-api-jdo-3.2.6.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-digester-1.8.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-annotations-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jtransforms-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jodd-core-3.5.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/snakeyaml-1.15.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-cli-1.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/parquet-format-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-configuration-1.6.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jpam-1.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/kryo-shaded-4.0.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/zookeeper-3.4.6.jar\n","spark-2.4.0-bin-hadoop2.7/jars/javax.ws.rs-api-2.0.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jackson-core-asl-1.9.13.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-core-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/json4s-scalap_2.11-3.5.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-kvstore_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/avro-1.8.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-yarn-api-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/api-asn1-api-1.0.0-M20.jar\n","spark-2.4.0-bin-hadoop2.7/jars/paranamer-2.8.jar\n","spark-2.4.0-bin-hadoop2.7/jars/RoaringBitmap-0.5.11.jar\n","spark-2.4.0-bin-hadoop2.7/jars/janino-3.0.9.jar\n","spark-2.4.0-bin-hadoop2.7/jars/stringtemplate-3.2.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/apacheds-i18n-2.0.0-M15.jar\n","spark-2.4.0-bin-hadoop2.7/jars/apache-log4j-extras-1.2.17.jar\n","spark-2.4.0-bin-hadoop2.7/jars/xbean-asm6-shaded-4.8.jar\n","spark-2.4.0-bin-hadoop2.7/jars/curator-recipes-2.7.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/oro-2.0.8.jar\n","spark-2.4.0-bin-hadoop2.7/jars/javax.annotation-api-1.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/chill_2.11-0.9.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-mllib_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hive-exec-1.2.1.spark2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-common-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-dbcp-1.4.jar\n","spark-2.4.0-bin-hadoop2.7/jars/mesos-1.4.0-shaded-protobuf.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-core_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/okio-1.13.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jackson-databind-2.6.7.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/netty-all-4.1.17.Final.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-compiler-3.0.9.jar\n","spark-2.4.0-bin-hadoop2.7/jars/parquet-hadoop-1.10.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-math3-3.4.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/httpclient-4.5.6.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jul-to-slf4j-1.7.16.jar\n","spark-2.4.0-bin-hadoop2.7/jars/stax-api-1.0-2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/core-1.1.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-codec-1.10.jar\n","spark-2.4.0-bin-hadoop2.7/jars/gson-2.2.4.jar\n","spark-2.4.0-bin-hadoop2.7/jars/zstd-jni-1.3.2-2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/javolution-5.5.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/univocity-parsers-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/apacheds-kerberos-codec-2.0.0-M15.jar\n","spark-2.4.0-bin-hadoop2.7/jars/kubernetes-client-3.0.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/parquet-common-1.10.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-yarn-server-common-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/libfb303-0.9.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/orc-mapreduce-1.5.2-nohive.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jersey-client-2.22.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/xercesImpl-2.9.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-collections-3.2.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/machinist_2.11-0.6.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/htrace-core-3.1.0-incubating.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jta-1.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/osgi-resource-locator-1.0.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/datanucleus-rdbms-3.2.9.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-unsafe_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/javassist-3.18.1-GA.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spire-macros_2.11-0.13.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/calcite-linq4j-1.2.0-incubating.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jline-2.14.6.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-launcher_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-client-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hive-metastore-1.2.1.spark2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-yarn-server-web-proxy-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spire_2.11-0.13.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jackson-core-2.6.7.jar\n","spark-2.4.0-bin-hadoop2.7/jars/api-util-1.0.0-M20.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-httpclient-3.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/orc-core-1.5.2-nohive.jar\n","spark-2.4.0-bin-hadoop2.7/jars/aircompressor-0.10.jar\n","spark-2.4.0-bin-hadoop2.7/jars/guice-servlet-3.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/scala-xml_2.11-1.0.5.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-common-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-hive_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/protobuf-java-2.5.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/parquet-jackson-1.10.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-sketch_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hive-beeline-1.2.1.spark2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-network-common_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-beanutils-core-1.8.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/stream-2.7.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-compress-1.8.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/macro-compat_2.11-1.1.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/activation-1.1.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/breeze-macros_2.11-0.13.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/derby-10.12.1.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/shapeless_2.11-2.3.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/minlog-1.3.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-logging-1.1.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-sql_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-mllib-local_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hive-cli-1.2.1.spark2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/metrics-core-3.1.5.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jackson-module-scala_2.11-2.6.7.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/automaton-1.11-8.jar\n","spark-2.4.0-bin-hadoop2.7/jars/objenesis-2.5.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/json4s-core_2.11-3.5.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/py4j-0.10.7.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jetty-6.1.26.jar\n","spark-2.4.0-bin-hadoop2.7/jars/slf4j-api-1.7.16.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-io-2.4.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jackson-xc-1.9.13.jar\n","spark-2.4.0-bin-hadoop2.7/jars/scala-reflect-2.11.12.jar\n","spark-2.4.0-bin-hadoop2.7/jars/xmlenc-0.52.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-yarn_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jetty-util-6.1.26.jar\n","spark-2.4.0-bin-hadoop2.7/jars/ivy-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/scala-library-2.11.12.jar\n","spark-2.4.0-bin-hadoop2.7/jars/snappy-0.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jsr305-1.3.9.jar\n","spark-2.4.0-bin-hadoop2.7/jars/arpack_combined_all-0.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/stax-api-1.0.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-app-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hk2-api-2.4.0-b34.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jackson-dataformat-yaml-2.6.7.jar\n","spark-2.4.0-bin-hadoop2.7/jars/arrow-vector-0.10.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/flatbuffers-1.2.0-3f79e055.jar\n","spark-2.4.0-bin-hadoop2.7/jars/calcite-avatica-1.2.0-incubating.jar\n","spark-2.4.0-bin-hadoop2.7/jars/generex-1.0.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/JavaEWAH-0.3.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/parquet-encoding-1.10.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/javax.servlet-api-3.1.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-hdfs-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-auth-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/bin/\n","spark-2.4.0-bin-hadoop2.7/bin/beeline\n","spark-2.4.0-bin-hadoop2.7/bin/pyspark\n","spark-2.4.0-bin-hadoop2.7/bin/pyspark.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/find-spark-home\n","spark-2.4.0-bin-hadoop2.7/bin/spark-submit2.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/spark-class.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/run-example\n","spark-2.4.0-bin-hadoop2.7/bin/sparkR2.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/spark-sql2.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/spark-submit.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/run-example.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/sparkR.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/spark-class2.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/spark-submit\n","spark-2.4.0-bin-hadoop2.7/bin/sparkR\n","spark-2.4.0-bin-hadoop2.7/bin/spark-sql.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/load-spark-env.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/pyspark2.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/docker-image-tool.sh\n","spark-2.4.0-bin-hadoop2.7/bin/spark-shell\n","spark-2.4.0-bin-hadoop2.7/bin/find-spark-home.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/spark-shell.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/load-spark-env.sh\n","spark-2.4.0-bin-hadoop2.7/bin/spark-sql\n","spark-2.4.0-bin-hadoop2.7/bin/spark-shell2.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/spark-class\n","spark-2.4.0-bin-hadoop2.7/bin/beeline.cmd\n","spark-2.4.0-bin-hadoop2.7/RELEASE\n","spark-2.4.0-bin-hadoop2.7/R/\n","spark-2.4.0-bin-hadoop2.7/R/lib/\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/NAMESPACE\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/doc/\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/doc/sparkr-vignettes.Rmd\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/doc/sparkr-vignettes.html\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/doc/sparkr-vignettes.R\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/doc/index.html\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/DESCRIPTION\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/R/\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdb\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/R/SparkR\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdx\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/html/\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/html/R.css\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/html/00Index.html\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/help/\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/help/AnIndex\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdb\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/help/aliases.rds\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdx\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/help/paths.rds\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/profile/\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/profile/general.R\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/profile/shell.R\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/tests/\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/tests/testthat/\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/tests/testthat/test_basic.R\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/Meta/\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/Meta/vignette.rds\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/Meta/package.rds\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/Meta/Rd.rds\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/Meta/nsInfo.rds\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/Meta/hsearch.rds\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/Meta/features.rds\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/Meta/links.rds\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/worker/\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/worker/daemon.R\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/worker/worker.R\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/INDEX\n","spark-2.4.0-bin-hadoop2.7/R/lib/sparkr.zip\n","spark-2.4.0-bin-hadoop2.7/yarn/\n","spark-2.4.0-bin-hadoop2.7/yarn/spark-2.4.0-yarn-shuffle.jar\n","spark-2.4.0-bin-hadoop2.7/examples/\n","spark-2.4.0-bin-hadoop2.7/examples/jars/\n","spark-2.4.0-bin-hadoop2.7/examples/jars/spark-examples_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/examples/jars/scopt_2.11-3.7.0.jar\n","spark-2.4.0-bin-hadoop2.7/examples/src/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/als.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/pagerank.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/ranking_metrics_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_classification_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/tf_idf_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_regression_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/k_means_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/streaming_linear_regression_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_regression_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_classification_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/pca_rowmatrix_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/elementwise_product_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/stratified_sampling_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/multi_class_metrics_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/fpgrowth_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/binary_classification_metrics_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/sampled_rdds.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/kernel_density_estimation_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/svm_with_sgd_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/streaming_k_means_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/correlations.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/correlations_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/regression_metrics_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/naive_bayes_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_model.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/word2vec.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/recommendation_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/random_rdd_generation.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/bisecting_k_means_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/summary_statistics_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/word2vec_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/kmeans.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/standard_scaler_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/multi_label_metrics_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/svd_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/normalizer_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/power_iteration_clustering_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/isotonic_regression_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/parquet_inputformat.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/logistic_regression.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/rformula_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/min_max_scaler_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/min_hash_lsh_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_classification_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/tf_idf_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_regression_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/vector_slicer_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/als_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/cross_validator.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/onehot_encoder_estimator_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/generalized_linear_regression_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/random_forest_regressor_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/chisq_selector_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/max_abs_scaler_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/n_gram_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/elementwise_product_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/binarizer_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/imputer_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/correlation_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/count_vectorizer_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/multilayer_perceptron_classification.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/stopwords_remover_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/fpgrowth_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/kmeans_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/chi_square_test_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/aft_survival_regression.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/dct_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/dataframe_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/pca_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/pipeline_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/polynomial_expansion_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/tokenizer_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/estimator_transformer_param_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/naive_bayes_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/string_indexer_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/summarizer_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/bucketizer_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/vector_assembler_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/sql_transformer.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/feature_hasher_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/vector_indexer_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/train_validation_split.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/vector_size_hint_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/one_vs_rest_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_summary_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/bisecting_k_means_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/index_to_string_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/linearsvc.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/word2vec_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/standard_scaler_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/prefixspan_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/lda_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/normalizer_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/quantile_discretizer_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/random_forest_classifier_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/isotonic_regression_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/gaussian_mixture_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/transitive_closure.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/flume_wordcount.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/queue_stream.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/recoverable_network_wordcount.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/kafka_wordcount.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/hdfs_wordcount.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/direct_kafka_wordcount.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/stateful_network_wordcount.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/network_wordcount.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/sql_network_wordcount.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/network_wordjoinsentiments.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/wordcount.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/status_api_demo.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sql/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sql/basic.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sql/arrow.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sql/streaming/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sql/datasource.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sql/hive.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/kmeans.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sort.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/pi.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/avro_inputformat.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LinearRegression.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RegressionMetricsExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LinearRegressionWithSGDExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderEstimatorExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRegressionMetricsExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLinearRegressionWithSGDExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderEstimatorExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/RSparkSQLExample.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/glm.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/als.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/kmeans.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/mlp.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/lda.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/ml.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/naiveBayes.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/kstest.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/gbt.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/survreg.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/svmLinear.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/bisectingKmeans.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/gaussianMixture.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/isoreg.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/randomForest.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/decisionTree.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/logit.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/fpm.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/data-manipulation.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/streaming/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/streaming/structured_network_wordcount.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/dataframe.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/people.csv\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/users.avro\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/employees.json\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/full_user.avsc\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/people.json\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/people.txt\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/kv1.txt\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/users.parquet\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/users.orc\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/user.avsc\n","spark-2.4.0-bin-hadoop2.7/NOTICE\n","spark-2.4.0-bin-hadoop2.7/data/\n","spark-2.4.0-bin-hadoop2.7/data/graphx/\n","spark-2.4.0-bin-hadoop2.7/data/graphx/users.txt\n","spark-2.4.0-bin-hadoop2.7/data/graphx/followers.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/\n","spark-2.4.0-bin-hadoop2.7/data/mllib/gmm_data.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/multi-channel/\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/multi-channel/grayscale.jpg\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/multi-channel/BGRA.png\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/kittens/\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/kittens/DP153539.jpg\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/kittens/54893.jpg\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/kittens/not-image.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/kittens/DP802813.jpg\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/license.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/license.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/chr30.4.184.jpg\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/grayscale.jpg\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA_alpha_60.png\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA.png\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP153539.jpg\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/54893.jpg\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP802813.jpg\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/not-image.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/29.5.a_b_EGDP022204.jpg\n","spark-2.4.0-bin-hadoop2.7/data/mllib/sample_linear_regression_data.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/sample_lda_data.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/kmeans_data.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/sample_svm_data.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/streaming_kmeans_data_test.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/sample_kmeans_data.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/sample_multiclass_classification_data.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/sample_fpgrowth.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/pic_data.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/pagerank_data.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/sample_isotonic_regression_libsvm_data.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/als/\n","spark-2.4.0-bin-hadoop2.7/data/mllib/als/test.data\n","spark-2.4.0-bin-hadoop2.7/data/mllib/als/sample_movielens_ratings.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/sample_lda_libsvm_data.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/sample_binary_classification_data.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/ridge-data/\n","spark-2.4.0-bin-hadoop2.7/data/mllib/ridge-data/lpsa.data\n","spark-2.4.0-bin-hadoop2.7/data/mllib/sample_movielens_data.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/iris_libsvm.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/sample_libsvm_data.txt\n","spark-2.4.0-bin-hadoop2.7/data/streaming/\n","spark-2.4.0-bin-hadoop2.7/data/streaming/AFINN-111.txt\n","spark-2.4.0-bin-hadoop2.7/README.md\n","spark-2.4.0-bin-hadoop2.7/LICENSE\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cXXdhn2bPfBz","cellView":"form","executionInfo":{"status":"ok","timestamp":1633831261585,"user_tz":-420,"elapsed":29103,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"60e64d89-b613-4464-b121-4aee9dc88bd8"},"source":["#@title Mount to drive\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F2G2kPgFPtqw","executionInfo":{"status":"ok","timestamp":1633751725130,"user_tz":-420,"elapsed":425,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"3849f5ba-0e39-48c6-c411-25b6006a5117"},"source":["%cd '/content/gdrive/MyDrive/LDS9_K269_ONLINE_NgoThiNga/LDS9_K269_NgoThiNga_Cuoi_ky/Du lieu cung cap/womens-ecommerce-clothing-reviews'"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/LDS9_K269_ONLINE_NgoThiNga/LDS9_K269_NgoThiNga_Cuoi_ky/Du lieu cung cap/womens-ecommerce-clothing-reviews\n"]}]},{"cell_type":"code","metadata":{"id":"jWykVZaAP8by","cellView":"form"},"source":["#@title Import pakages\n","import pyspark\n","from pyspark import SparkContext\n","from pyspark.conf import SparkConf\n","from pyspark.sql import SparkSession\n","from pyspark.sql import SQLContext\n","from pyspark.sql.functions import col, explode\n","import pandas as pd\n","from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n","from pyspark.ml.feature import Binarizer,Bucketizer, OneHotEncoder, StringIndexer, Tokenizer, StopWordsRemover, CountVectorizer, IDF\n","from pyspark.sql.functions import isnan, count, regexp_extract, col, datediff, when, length, log, array, lit, trim\n","\n","from pyspark.ml.linalg import Vectors\n","from pyspark.ml.feature import VectorAssembler\n","\n","from pyspark.ml import Pipeline\n","from pyspark.ml.classification import DecisionTreeClassifier, DecisionTreeClassificationModel\n","from pyspark.ml.classification import LogisticRegression, LogisticRegressionModel, GBTClassifier\n","from pyspark.ml.classification import RandomForestClassifier, RandomForestClassificationModel\n","from pyspark.ml.classification import NaiveBayes, NaiveBayesModel\n","from pyspark.ml.classification import LinearSVC, LinearSVCModel\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bwjzPWkzQP9i"},"source":["sc = SparkContext()\n","spark = SparkSession.builder.appName('cau1').getOrCreate()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PM8gbNM3t3ds"},"source":["df = pd.read_excel(\"Womens_Clothing_E_Commerce_Reviews.xlsx\", index_col=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RREhzheKAvlA","executionInfo":{"status":"ok","timestamp":1633751738661,"user_tz":-420,"elapsed":31,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"d3ea5759-cc9e-49c6-fe38-de88d895fd2a"},"source":["df.info()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 23481 entries, 0 to 23480\n","Data columns (total 10 columns):\n"," #   Column                   Non-Null Count  Dtype \n","---  ------                   --------------  ----- \n"," 0   Clothing ID              23481 non-null  int64 \n"," 1   Age                      23481 non-null  int64 \n"," 2   Title                    19671 non-null  object\n"," 3   Review Text              22636 non-null  object\n"," 4   Rating                   23481 non-null  int64 \n"," 5   Recommended IND          23481 non-null  int64 \n"," 6   Positive Feedback Count  23481 non-null  int64 \n"," 7   Division Name            23467 non-null  object\n"," 8   Department Name          23467 non-null  object\n"," 9   Class Name               23467 non-null  object\n","dtypes: int64(5), object(5)\n","memory usage: 2.0+ MB\n"]}]},{"cell_type":"code","metadata":{"id":"iFmB-vsi9-fd"},"source":["df.dropna(subset=['Review Text'], axis=0, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"90Lk2rRPRIgp","colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","executionInfo":{"status":"ok","timestamp":1633788302723,"user_tz":-420,"elapsed":389,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"35e51aa8-e2d1-4b0c-a61d-a4a2954d7354"},"source":["#@title Create Spark DataFrame\n","schema = StructType([\n","                     StructField(\"Clothing ID\", IntegerType(), True),\n","                     StructField(\"Age\", IntegerType(), True),\n","                     StructField(\"Title\", StringType(), True),\n","                     StructField(\"Review Text\", StringType(), True),\n","                     StructField(\"Rating\", IntegerType(), True),\n","                     StructField(\"Recommended IND\", IntegerType(), True),\n","                     StructField(\"Positive Feedback Count\", IntegerType(), True),\n","                     StructField(\"Division Name\", StringType(), True),\n","                     StructField(\"Department Name\", StringType(), True),\n","                     StructField(\"Class Name\", StringType(), True),\n","                     \n","])\n","\n","data = spark.createDataFrame(df, schema = schema)\n","data.show(5, False)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+---+-----------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+---------------+-----------------------+--------------+---------------+----------+\n","|Clothing ID|Age|Title                  |Review Text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |Rating|Recommended IND|Positive Feedback Count|Division Name |Department Name|Class Name|\n","+-----------+---+-----------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+---------------+-----------------------+--------------+---------------+----------+\n","|767        |33 |NaN                    |Absolutely wonderful - silky and sexy and comfortable                                                                                                                                                                                                                                                                                                                                                                                                                                                               |4     |1              |0                      |Initmates     |Intimate       |Intimates |\n","|1080       |34 |NaN                    |Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.                                                                                                                                                                                                     |5     |1              |4                      |General       |Dresses        |Dresses   |\n","|1077       |60 |Some major design flaws|I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i could not zip it up! i reordered it in petite medium, which was just ok. overall, the top half was comfortable and fit nicely, but the bottom half had a very tight under layer and several somewhat cheap (net) over layers. imo, a major design flaw was the net over layer sewn directly into the zipper - it c|3     |0              |0                      |General       |Dresses        |Dresses   |\n","|1049       |50 |My favorite buy!       |I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!                                                                                                                                                                                                                                                                                                                                                                                        |5     |1              |0                      |General Petite|Bottoms        |Pants     |\n","|847        |47 |Flattering shirt       |This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!                                                                                                                                                                                                                                                                                                                    |5     |1              |6                      |General       |Tops           |Blouses   |\n","+-----------+---+-----------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+---------------+-----------------------+--------------+---------------+----------+\n","only showing top 5 rows\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zetJB4FlXXis","executionInfo":{"status":"ok","timestamp":1633780670340,"user_tz":-420,"elapsed":14,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"3ebc90cd-4c5d-4a06-eedf-b15a5960aec9"},"source":["data.count()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["22636"]},"metadata":{},"execution_count":309}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xeccV_1PPIxt","executionInfo":{"status":"ok","timestamp":1633780670852,"user_tz":-420,"elapsed":16,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"ed49835a-0cdf-40a6-9894-1db3da4a29b0"},"source":["data.printSchema()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- Clothing ID: integer (nullable = true)\n"," |-- Age: integer (nullable = true)\n"," |-- Title: string (nullable = true)\n"," |-- Review Text: string (nullable = true)\n"," |-- Rating: integer (nullable = true)\n"," |-- Recommended IND: integer (nullable = true)\n"," |-- Positive Feedback Count: integer (nullable = true)\n"," |-- Division Name: string (nullable = true)\n"," |-- Department Name: string (nullable = true)\n"," |-- Class Name: string (nullable = true)\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":359},"id":"K2GQ4pN-Qufi","executionInfo":{"status":"ok","timestamp":1633780672308,"user_tz":-420,"elapsed":1462,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"64c77e06-ed89-44e3-9744-1ef135aa9dfe"},"source":["# Kiểm tra dữ liệu nan\n","data.select([count(when(isnan(c), c)).alias(c) for c in data.columns]).toPandas().T\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Clothing ID</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Age</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Title</th>\n","      <td>2966</td>\n","    </tr>\n","    <tr>\n","      <th>Review Text</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Rating</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Recommended IND</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Positive Feedback Count</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Division Name</th>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>Department Name</th>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>Class Name</th>\n","      <td>13</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                            0\n","Clothing ID                 0\n","Age                         0\n","Title                    2966\n","Review Text                 0\n","Rating                      0\n","Recommended IND             0\n","Positive Feedback Count     0\n","Division Name              13\n","Department Name            13\n","Class Name                 13"]},"metadata":{},"execution_count":311}]},{"cell_type":"code","metadata":{"id":"sbzJu_UnAJwg"},"source":["# def to_null(c):\n","#     return when(~(col(c).isNull() | isnan(col(c)) | (trim(col(c)) == \" \")), col(c))\n","\n","\n","# data.select(to_null('Review Text').alias('Review Text_notnull')).na.drop().show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F9tarjH0VeL7","colab":{"base_uri":"https://localhost:8080/","height":359},"executionInfo":{"status":"ok","timestamp":1633780674936,"user_tz":-420,"elapsed":18,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"a7df60ca-92bf-44b8-ae85-70959bdb5303"},"source":["data.select([count(when(col(c).isNull(), c)).alias(c) for c in data.columns]).toPandas().T"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Clothing ID</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Age</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Title</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Review Text</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Rating</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Recommended IND</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Positive Feedback Count</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Division Name</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Department Name</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Class Name</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                         0\n","Clothing ID              0\n","Age                      0\n","Title                    0\n","Review Text              0\n","Rating                   0\n","Recommended IND          0\n","Positive Feedback Count  0\n","Division Name            0\n","Department Name          0\n","Class Name               0"]},"metadata":{},"execution_count":313}]},{"cell_type":"code","metadata":{"id":"yLxxHUYkMetN"},"source":["data = data.withColumn('class', when(data.Rating > 4, 'like'). when(data.Rating <=2,  'Not_like').otherwise(\"neutral\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-N6E0tZdRCmz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633780675475,"user_tz":-420,"elapsed":20,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"8146d629-c54f-4fdf-c89b-a122d90e9f9a"},"source":["# Create length column\n","data = data.withColumn('length', length(data['Review Text']))\n","data = data.withColumn('log_Length', log(col('length')))\n","data = data.select(\"Review Text\", \"Rating\", \"class\",'Age', 'log_Length','Positive Feedback Count')\n","data.show(3)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+------+-------+---+-----------------+-----------------------+\n","|         Review Text|Rating|  class|Age|       log_Length|Positive Feedback Count|\n","+--------------------+------+-------+---+-----------------+-----------------------+\n","|Absolutely wonder...|     4|neutral| 33|3.970291913552122|                      0|\n","|Love this dress! ...|     5|   like| 34|5.713732805509369|                      4|\n","|I had such high h...|     3|neutral| 60|6.214608098422191|                      0|\n","+--------------------+------+-------+---+-----------------+-----------------------+\n","only showing top 3 rows\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kR5QVZKn_OhN","executionInfo":{"status":"ok","timestamp":1633780689957,"user_tz":-420,"elapsed":1475,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"5b32ec74-605a-4120-dbb7-cdac8774ae37"},"source":["data.groupby('class').mean('log_Length','Positive Feedback Count').show()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------+------------------+----------------------------+\n","|   class|   avg(log_Length)|avg(Positive Feedback Count)|\n","+--------+------------------+----------------------------+\n","| neutral|5.6490521610621585|          2.7464096260835813|\n","|    like| 5.541685470992448|          2.4083260228088363|\n","|Not_like| 5.620096081190402|          3.4239864864864864|\n","+--------+------------------+----------------------------+\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BDLlaBP2fblD","executionInfo":{"status":"ok","timestamp":1633780700311,"user_tz":-420,"elapsed":1544,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"bbf74bd3-6613-480d-b7b0-7333e7843a47"},"source":["data.groupby('class').count().show()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------+-----+\n","|   class|count|\n","+--------+-----+\n","| neutral| 7729|\n","|    like|12539|\n","|Not_like| 2368|\n","+--------+-----+\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"5wagO-gKA7NY"},"source":["## Feature Transformation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YNBdmBIbAI2f","executionInfo":{"status":"ok","timestamp":1633782310235,"user_tz":-420,"elapsed":1501,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"42494517-8f8e-47c7-bff3-4a99f6dd8589"},"source":["indexer = StringIndexer(inputCol='class', outputCol='label')\n","# Indexer identifies categories in the data\n","indexer_model = indexer.fit(data)\n","# Indexer creates a new column with numeric index values\n","data_final = indexer_model.transform(data)\n","data_final.groupBy(['label','class']).count().show(3)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+--------+-----+\n","|label|   class|count|\n","+-----+--------+-----+\n","|  0.0|    like|12539|\n","|  1.0| neutral| 7729|\n","|  2.0|Not_like| 2368|\n","+-----+--------+-----+\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EZWz5MwSAs2W","executionInfo":{"status":"ok","timestamp":1633782335243,"user_tz":-420,"elapsed":352,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"7e4d63df-f25b-4985-8e31-9af1115d7549"},"source":["data_final.show(3)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+------+-------+---+-----------------+-----------------------+-----+\n","|         Review Text|Rating|  class|Age|       log_Length|Positive Feedback Count|label|\n","+--------------------+------+-------+---+-----------------+-----------------------+-----+\n","|Absolutely wonder...|     4|neutral| 33|3.970291913552122|                      0|  1.0|\n","|Love this dress! ...|     5|   like| 34|5.713732805509369|                      4|  0.0|\n","|I had such high h...|     3|neutral| 60|6.214608098422191|                      0|  1.0|\n","+--------------------+------+-------+---+-----------------+-----------------------+-----+\n","only showing top 3 rows\n","\n"]}]},{"cell_type":"code","metadata":{"id":"y7XSVukdAmBf"},"source":["# Chuẩn hóa dữ liệu 'Review Text'\n","tokenizer = Tokenizer(inputCol='Review Text', outputCol='token_text')\n","stopremove = StopWordsRemover(inputCol='token_text', outputCol='stop_tokens')\n","count_vec = CountVectorizer(inputCol='stop_tokens', outputCol='cv')\n","idf = IDF(inputCol='cv', outputCol='tf-idf')\n","#class_to_num = StringIndexer(inputCol='class', outputCol='label')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-QBZAcKPBGK3"},"source":["assembler = VectorAssembler(inputCols=['tf-idf','Age','log_Length','Positive Feedback Count'],\n","                           outputCol='features')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gloV2gyAO3AR"},"source":["## Tạo tập dữ liệu Train và Test"]},{"cell_type":"code","metadata":{"id":"eUfo07yvB-UB"},"source":["data_final = data_final.select(\"Review Text\",'Age', 'log_Length','Positive Feedback Count', 'label')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nz9BFUoq6CsZ"},"source":["training, testing = data_final.randomSplit([0.8,0.2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rvnUHMWvefUi"},"source":["#training.groupBy('label').count().show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CR9cXbcUefiM"},"source":["# testing.groupBy('label').count().show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0iC_qjNDGc1u"},"source":["## Áp dụng các mô hình Classification\n","+ Logistic Regression\n","+ Naive Bayes\n","+ RandomForest\n","+ DecisionTree\n"]},{"cell_type":"code","metadata":{"id":"2puVMg5_GTxC"},"source":["# init classification model\n","lg = LogisticRegression(featuresCol = \"features\",\n","                      labelCol = \"label\", \n","                      maxIter = 20, \n","                      regParam=0.3, \n","                      predictionCol = \"prediction\")\n","nb = NaiveBayes(featuresCol = \"features\",\n","                smoothing=1.0,\n","                modelType=\"multinomial\",\n","                labelCol = \"label\",\n","                predictionCol = \"prediction\")\n","rf = RandomForestClassifier(featuresCol = \"features\", \n","                      labelCol = \"label\",\n","                      numTrees=500,\n","                      maxDepth = 5,\n","                      maxBins = 64,\n","                      predictionCol = \"prediction\")\n","ds = DecisionTreeClassifier(featuresCol = \"features\",\n","                      labelCol = \"label\",\n","                      predictionCol = \"prediction\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vALNc__a39DU"},"source":["# init pipeline for models\n","# logisticRegression pipeline\n","pipeline_lg = Pipeline(stages=[tokenizer,\n","                            stopremove,\n","                            count_vec,\n","                            idf,\n","                            assembler, lg])\n","\n","# Naive Bayes pipeline\n","pipeline_nb = Pipeline(stages=[tokenizer,\n","                            stopremove,\n","                            count_vec,\n","                            idf,\n","                            assembler, nb])\n","\n","# RandomForest pipeline\n","pipeline_rf = Pipeline(stages=[tokenizer,\n","                            stopremove,\n","                            count_vec,\n","                            idf,\n","                            assembler, rf])\n","\n","# DecisionTree pipeline\n","pipeline_ds = Pipeline(stages=[tokenizer,\n","                            stopremove,\n","                            count_vec,\n","                            idf,\n","                            assembler, ds])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TWaB6hE15xU0"},"source":["# fit pipeline\n","lg_model = pipeline_lg.fit(training)\n","nb_model = pipeline_nb.fit(training)\n","rf_model = pipeline_rf.fit(training)\n","ds_model = pipeline_ds.fit(training)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MpN45j8c8yXn"},"source":["#apply transform\n","test_result_lg = lg_model.transform(testing)\n","test_result_nb = nb_model.transform(testing)\n","test_result_rf = rf_model.transform(testing)\n","test_result_ds = ds_model.transform(testing)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BkDJJIZyRUqo","executionInfo":{"status":"ok","timestamp":1633784899451,"user_tz":-420,"elapsed":10084,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"02d5b3ef-ef13-4e5d-a9fb-4fe2d8f68f1b"},"source":["# avaluate models\n","acc_eval = MulticlassClassificationEvaluator(labelCol=\"label\",\n","                                        predictionCol=\"prediction\",\n","                                        metricName=\"accuracy\")\n","acc_lg = acc_eval.evaluate(test_result_lg)\n","print(\"Accuracy of Logistic model at predicting product's rating: {0:2.2f}%\".format(acc_lg*100))\n","print('-'*80)\n","acc_nb = acc_eval.evaluate(test_result_nb)\n","print(\"Accuracy of Naive Bayes model at predicting product's rating: {0:2.2f}%\".format(acc_nb*100))\n","print('-'*80)\n","acc_rf = acc_eval.evaluate(test_result_rf)\n","print(\"Accuracy of Random Forest model at predicting product's rating: {0:2.2f}%\".format(acc_rf*100))\n","print('-'*80)\n","acc_ds = acc_eval.evaluate(test_result_ds)\n","print(\"Accuracy of Decision Tree model at predicting product's rating: {0:2.2f}%\".format(acc_ds*100))\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of Logistic model at predicting product's rating: 67.87%\n","--------------------------------------------------------------------------------\n","Accuracy of Naive Bayes model at predicting product's rating: 66.31%\n","--------------------------------------------------------------------------------\n","Accuracy of Random Forest model at predicting product's rating: 55.54%\n","--------------------------------------------------------------------------------\n","Accuracy of Decision Tree model at predicting product's rating: 57.47%\n"]}]},{"cell_type":"markdown","metadata":{"id":"CuEn4OZNUFjY"},"source":["**Lựa chọn LogisticRegression model**"]},{"cell_type":"code","metadata":{"id":"l68I7oVhTWm3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633786866532,"user_tz":-420,"elapsed":11417,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"6a1c652d-adfa-4fa5-9a19-8bb030b4ccb8"},"source":["# Create a confusion matrix\n","test_result_lg.groupBy('label', 'prediction').count().show()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+----------+-----+\n","|label|prediction|count|\n","+-----+----------+-----+\n","|  2.0|       0.0|  122|\n","|  1.0|       1.0|  804|\n","|  0.0|       1.0|  294|\n","|  1.0|       0.0|  721|\n","|  2.0|       2.0|   62|\n","|  2.0|       1.0|  294|\n","|  1.0|       2.0|   46|\n","|  0.0|       0.0| 2262|\n","|  0.0|       2.0|    4|\n","+-----+----------+-----+\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"_DrwmApRxyde"},"source":["**Nhận xét:**\n","+ Accuracy trên các model còn thấp\n","+ Cần cân bằng lại dữ liệu, để cải thiện model"]},{"cell_type":"markdown","metadata":{"id":"9xO2d59wxkU5"},"source":["## Cân bằng lại dữ liệu trên tập training\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"joo5W_uZ_QWa","executionInfo":{"status":"ok","timestamp":1633786236757,"user_tz":-420,"elapsed":1731,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"e5252530-fc2a-4558-aac1-9e05b27eb3ea"},"source":["like_df = training.filter(col(\"label\") == 0.0) \n","neutral_df = training.filter(col(\"label\") == 1.0) \n","not_like_df = training.filter(col(\"label\") == 2.0) \n","ratio_1 = int(like_df.count()/neutral_df.count()) \n","ratio_2 = int(like_df.count()/not_like_df.count()) \n","print(\"ratio like/neutral: {}\".format(ratio_1)) \n","print(\"ratio like/not_like: {}\".format(ratio_2))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ratio like/neutral: 1\n","ratio like/not_like: 5\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5yYmPdB1yHXJ","executionInfo":{"status":"ok","timestamp":1633786236758,"user_tz":-420,"elapsed":17,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"84de0239-e50f-4011-9f35-b36aff0a9092"},"source":["# Resample neutral\n","a1 = range(ratio_1)\n","#duplicate the minority rows\n","oversampled_neutral_df = neutral_df.withColumn('dummy',\n","                                              explode(array([lit(x) for x in a1]))).drop('dummy')\n","# combine both oversampled minority rows and previous majority rows\n","traning_resample = like_df.unionAll(oversampled_neutral_df)\n","traning_resample.show(5)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+---+-----------------+-----------------------+-----+\n","|         Review Text|Age|       log_Length|Positive Feedback Count|label|\n","+--------------------+---+-----------------+-----------------------+-----+\n","|-like others, i a...| 34|5.541263545158426|                      1|  0.0|\n","|...on this great ...| 37| 4.48863636973214|                      2|  0.0|\n","|1. i'm 5'5\" tall,...| 57|4.382026634673881|                      5|  0.0|\n","|1. i'm 5'5\" tall,...| 57|6.206575926724928|                     19|  0.0|\n","|1. i'm 5'5\" tall,...| 57|6.214608098422191|                     19|  0.0|\n","+--------------------+---+-----------------+-----------------------+-----+\n","only showing top 5 rows\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6g_eYTWzyHaP","executionInfo":{"status":"ok","timestamp":1633786240472,"user_tz":-420,"elapsed":1620,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"013c3002-ddef-4de1-ae4e-1e15b60fa781"},"source":["traning_resample.groupBy('label').count().show()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+-----+\n","|label|count|\n","+-----+-----+\n","|  0.0| 9979|\n","|  1.0| 6158|\n","+-----+-----+\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LcePJAOyyHc2","executionInfo":{"status":"ok","timestamp":1633786242459,"user_tz":-420,"elapsed":514,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"e14cf7ae-7f31-4b3c-f537-2ce6c03faaa4"},"source":["# Resample not_like\n","a2 = range(ratio_2)\n","#duplicate the minority rows\n","oversampled_notlike_df = not_like_df.withColumn('dummy',\n","                                              explode(array([lit(x) for x in a2]))).drop('dummy')\n","# combine both oversampled minority rows and previous majority rows\n","traning_resample = traning_resample.unionAll(oversampled_notlike_df)\n","traning_resample.show(5)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+---+-----------------+-----------------------+-----+\n","|         Review Text|Age|       log_Length|Positive Feedback Count|label|\n","+--------------------+---+-----------------+-----------------------+-----+\n","|-like others, i a...| 34|5.541263545158426|                      1|  0.0|\n","|...on this great ...| 37| 4.48863636973214|                      2|  0.0|\n","|1. i'm 5'5\" tall,...| 57|4.382026634673881|                      5|  0.0|\n","|1. i'm 5'5\" tall,...| 57|6.206575926724928|                     19|  0.0|\n","|1. i'm 5'5\" tall,...| 57|6.214608098422191|                     19|  0.0|\n","+--------------------+---+-----------------+-----------------------+-----+\n","only showing top 5 rows\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D7Eqyb8ayHfk","executionInfo":{"status":"ok","timestamp":1633786246235,"user_tz":-420,"elapsed":1958,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"43547c1c-f548-48e7-d693-8fc190a10dcb"},"source":["traning_resample.groupBy('label').count().show()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+-----+\n","|label|count|\n","+-----+-----+\n","|  0.0| 9979|\n","|  1.0| 6158|\n","|  2.0| 9450|\n","+-----+-----+\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"RszeZxbwTp9w"},"source":["**Áp dụng model cho dữ liệu sau khi cân bằng**"]},{"cell_type":"code","metadata":{"id":"UNMzUakUEWrR"},"source":["# Fit models on resampled training set\n","lg_model_2 = pipeline_lg.fit(traning_resample)\n","nb_model_2 = pipeline_nb.fit(traning_resample)\n","rf_model_2 = pipeline_rf.fit(traning_resample)\n","ds_model_2 = pipeline_ds.fit(traning_resample)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eF6Cablt1oxf"},"source":["# apply transform\n","test_result_lg_2 = lg_model_2.transform(testing)\n","test_result_nb_2 = nb_model_2.transform(testing)\n","test_result_rf_2 = rf_model_2.transform(testing)\n","test_result_ds_2 = ds_model_2.transform(testing)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zdgGlJFR1o0-","executionInfo":{"status":"ok","timestamp":1633786716740,"user_tz":-420,"elapsed":10776,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"8f8745be-fc7a-4dd2-e4a3-2b449c28d013"},"source":["# avaluate models\n","acc_eval = MulticlassClassificationEvaluator(labelCol=\"label\",\n","                                        predictionCol=\"prediction\",\n","                                        metricName=\"accuracy\")\n","acc_lg_2 = acc_eval.evaluate(test_result_lg_2)\n","print(\"Accuracy of Logistic model at predicting product's rating: {0:2.2f}%\".format(acc_lg_2*100))\n","print('-'*80)\n","acc_nb_2 = acc_eval.evaluate(test_result_nb_2)\n","print(\"Accuracy of Naive Bayes model at predicting product's rating: {0:2.2f}%\".format(acc_nb_2*100))\n","print('-'*80)\n","acc_rf_2 = acc_eval.evaluate(test_result_rf_2)\n","print(\"Accuracy of Random Forest model at predicting product's rating: {0:2.2f}%\".format(acc_rf_2*100))\n","print('-'*80)\n","acc_ds_2 = acc_eval.evaluate(test_result_ds_2)\n","print(\"Accuracy of Decision Tree model at predicting product's rating: {0:2.2f}%\".format(acc_ds_2*100))\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of Logistic model at predicting product's rating: 66.57%\n","--------------------------------------------------------------------------------\n","Accuracy of Naive Bayes model at predicting product's rating: 64.92%\n","--------------------------------------------------------------------------------\n","Accuracy of Random Forest model at predicting product's rating: 60.38%\n","--------------------------------------------------------------------------------\n","Accuracy of Decision Tree model at predicting product's rating: 47.04%\n"]}]},{"cell_type":"markdown","metadata":{"id":"JdMTt2deUWFj"},"source":["**Lựa chọn LogisticRegression model**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9LjjFOWURc3e","executionInfo":{"status":"ok","timestamp":1633786763493,"user_tz":-420,"elapsed":11420,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"3b9029bc-8948-4a67-c459-f37970e2d0fb"},"source":["# Create a confusion matrix\n","test_result_lg_2.groupBy('label', 'prediction').count().show()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+----------+-----+\n","|label|prediction|count|\n","+-----+----------+-----+\n","|  2.0|       0.0|   65|\n","|  1.0|       1.0|  536|\n","|  0.0|       1.0|  271|\n","|  1.0|       0.0|  653|\n","|  2.0|       2.0|  304|\n","|  2.0|       1.0|  109|\n","|  1.0|       2.0|  382|\n","|  0.0|       0.0| 2228|\n","|  0.0|       2.0|   61|\n","+-----+----------+-----+\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"wdNVHeqQIyZj"},"source":["**Nhận xét:**\n","+ Sau khi resample lại các class, độ chính xác của các model không được cải thiện.\n","+ Tuy nhiên model 2 dự đoán tốt hơn trên các class 0, 1, 2 so với model 1 khi chưa cân bằng dữ liệu. Vì vậy ta chọn model 2 cho việc dự đoán trên tập dữ liệu mới."]},{"cell_type":"markdown","metadata":{"id":"ixXmmVy5TTDg"},"source":["## Lựa chọn model\n","+ LogisticRegression model có độ chính xác 66.57%, cao nhất trong các model đã sử dụng\n","+ Chọn LogisticRegression để  dự đoán"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C2jhp8cT2Spu","executionInfo":{"status":"ok","timestamp":1633787446610,"user_tz":-420,"elapsed":1475,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"8c266160-ad7c-4959-85dc-4ca8ae4ebfd7"},"source":["test_result_lg_2.groupBy('label').count().show()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+-----+\n","|label|count|\n","+-----+-----+\n","|  0.0| 2560|\n","|  1.0| 1571|\n","|  2.0|  478|\n","+-----+-----+\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZVXAy3cYibZM","executionInfo":{"status":"ok","timestamp":1633787446958,"user_tz":-420,"elapsed":10,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"ecdf622c-6cab-4a9d-a818-2f350cd3c332"},"source":["print('Accuracy of model: ', round(acc_lg_2*100,2), '%')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of model:  66.57 %\n"]}]},{"cell_type":"markdown","metadata":{"id":"Eaf2ax208I1G"},"source":["## Xử lý dữ liệu từ sheet \"new_reviews\" và áp dụng model để dự đoán trên dữ liệu mới"]},{"cell_type":"markdown","metadata":{"id":"GWoONRJj8PIE"},"source":["**Tiền xử lý \"new_reviews\"**"]},{"cell_type":"code","metadata":{"id":"DoXpPpDl8_Dl"},"source":["df_new = pd.read_excel(\"Womens_Clothing_E_Commerce_Reviews.xlsx\", index_col=0, sheet_name='new_reviews')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iKrwt2cSAkYs"},"source":["schema = StructType([\n","                     StructField(\"Clothing ID\", IntegerType(), True),\n","                     StructField(\"Age\", IntegerType(), True),\n","                     StructField(\"Title\", StringType(), True),\n","                     StructField(\"Review Text\", StringType(), True),\n","                     StructField(\"Recommended IND\", IntegerType(), True),\n","                     StructField(\"Positive Feedback Count\", IntegerType(), True),\n","                     StructField(\"Division Name\", StringType(), True),\n","                     StructField(\"Department Name\", StringType(), True),\n","                     StructField(\"Class Name\", StringType(), True),\n","                     \n","])\n","data_new = spark.createDataFrame(df_new, schema = schema)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MHoLQe1IAp1g","executionInfo":{"status":"ok","timestamp":1633785744452,"user_tz":-420,"elapsed":18,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"96b0d0a3-0a34-4316-8821-6326cdf88a42"},"source":["data_new.show()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+---+--------------------+--------------------+---------------+-----------------------+-------------+---------------+----------+\n","|Clothing ID|Age|               Title|         Review Text|Recommended IND|Positive Feedback Count|Division Name|Department Name|Class Name|\n","+-----------+---+--------------------+--------------------+---------------+-----------------------+-------------+---------------+----------+\n","|       1077| 53|Dress looks like ...|Dress runs small ...|              0|                     14|      General|        Dresses|   Dresses|\n","|        862| 66|            Cute top|Nice top. armhole...|              1|                      2|      General|           Tops|     Knits|\n","|       1080| 31|        Underwhelmed|Was really excite...|              0|                      1|      General|        Dresses|   Dresses|\n","|        936| 35|  Absolutely perfect|If you are going ...|              0|                      9|      General|           Tops|  Sweaters|\n","|        872| 35|   Cute comfy casual|I saw this online...|              1|                      0|      General|           Tops|     Knits|\n","+-----------+---+--------------------+--------------------+---------------+-----------------------+-------------+---------------+----------+\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":328},"id":"ZKOiQkFvBK1p","executionInfo":{"status":"ok","timestamp":1633785748318,"user_tz":-420,"elapsed":491,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"902990fa-e27c-44db-efff-831a521590c0"},"source":["# Kiểm tra dữ liệu null\n","data_new.select([count(when(isnan(c), c)).alias(c) for c in data_new.columns]).toPandas().T\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Clothing ID</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Age</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Title</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Review Text</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Recommended IND</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Positive Feedback Count</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Division Name</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Department Name</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Class Name</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                         0\n","Clothing ID              0\n","Age                      0\n","Title                    0\n","Review Text              0\n","Recommended IND          0\n","Positive Feedback Count  0\n","Division Name            0\n","Department Name          0\n","Class Name               0"]},"metadata":{},"execution_count":399}]},{"cell_type":"code","metadata":{"id":"mKKHfpFPUj9D"},"source":["# => Không có dữ liệu nan"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":328},"id":"7z2ClHboBYNl","executionInfo":{"status":"ok","timestamp":1633785749544,"user_tz":-420,"elapsed":556,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"91c5a865-c85d-4f79-d07f-5e31aa4f9289"},"source":["data_new.select([count(when(col(c).isNull(), c)).alias(c) for c in data_new.columns]).toPandas().T"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Clothing ID</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Age</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Title</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Review Text</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Recommended IND</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Positive Feedback Count</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Division Name</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Department Name</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Class Name</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                         0\n","Clothing ID              0\n","Age                      0\n","Title                    0\n","Review Text              0\n","Recommended IND          0\n","Positive Feedback Count  0\n","Division Name            0\n","Department Name          0\n","Class Name               0"]},"metadata":{},"execution_count":400}]},{"cell_type":"code","metadata":{"id":"ZvgH0bIQUnaN"},"source":["# => không có dữ liệu null"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"alB_toIyBgzK","executionInfo":{"status":"ok","timestamp":1633787532199,"user_tz":-420,"elapsed":339,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"eb134eb8-fb30-4ff0-fc17-6368a64eebaa"},"source":["# Create length column\n","data_new = data_new.withColumn('length', length(data_new['Review Text']))\n","data_new = data_new.withColumn('log_Length', log(col('length')))\n","data_new.show()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+---+-----------------+-----------------------+------+\n","|         Review Text|Age|       log_Length|Positive Feedback Count|length|\n","+--------------------+---+-----------------+-----------------------+------+\n","|Dress runs small ...| 53|5.817111159963204|                     14|   336|\n","|Nice top. armhole...| 66|6.104793232414985|                      2|   448|\n","|Was really excite...| 31|5.998936561946683|                      1|   403|\n","|If you are going ...| 35|5.786897381366708|                      9|   326|\n","|I saw this online...| 35|5.707110264748875|                      0|   301|\n","+--------------------+---+-----------------+-----------------------+------+\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"953Sb_SsDK3U","executionInfo":{"status":"ok","timestamp":1633787539333,"user_tz":-420,"elapsed":367,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"00b00718-6287-40a3-d1dd-c817e08e704e"},"source":["# Lựa chọn thuộc tính phù hợp với tập đã train\n","data_new = data_new.select(\"Review Text\", 'Age', 'log_Length','Positive Feedback Count')\n","data_new.show(3)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+---+-----------------+-----------------------+\n","|         Review Text|Age|       log_Length|Positive Feedback Count|\n","+--------------------+---+-----------------+-----------------------+\n","|Dress runs small ...| 53|5.817111159963204|                     14|\n","|Nice top. armhole...| 66|6.104793232414985|                      2|\n","|Was really excite...| 31|5.998936561946683|                      1|\n","+--------------------+---+-----------------+-----------------------+\n","only showing top 3 rows\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yJM_x0HiEd3S","executionInfo":{"status":"ok","timestamp":1633787584406,"user_tz":-420,"elapsed":832,"user":{"displayName":"Ngô Thị Nga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghdbo_uSgq4hHmjO8Vk9VkhzmEkRtwGQnOOrHqMqw=s64","userId":"05213848261791160861"}},"outputId":"d7cc995c-bcd9-4f2a-e09b-c330d076c3a4"},"source":["# Check dataset with LogisticRegression model\n","predictions = lg_model_2.transform(data_new)\n","predictions.select('Review Text','probability','prediction').show(truncate=False)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------+----------+\n","|Review Text                                                                                                                                                                                                                                                                                                                                                                                                                                                     |probability                                                 |prediction|\n","+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------+----------+\n","|Dress runs small esp where the zipper area runs. i ordered the sp which typically fits me and it was very tight! the material on the top looks and feels very cheap that even just pulling on it will cause it to rip the fabric. pretty disappointed as it was going to be my christmas dress this year! needless to say it will be going back.                                                                                                                |[0.03619223334523996,0.10404585448170832,0.8597619121730518]|2.0       |\n","|Nice top. armholes are a bit oversized but as an older woman, i'm picky about that. the print is pretty and unusual. it just didn't look great on me. there's a slight peplum in the back that hangs nicely. it's a lightweight tee fabric that's opaque. i tried it on with a black bra which was barely visible. great for warmer climates but there are so many gorgeous tops out now, that i decided to return since summer is winding down. i do recommend.|[0.4875280518395541,0.3580315633059587,0.1544403848544872]  |0.0       |\n","|Was really excited for this dress but should have paid more attention to the material it was made with. for the price of the dress, it felt very cheap. i didn't even end up trying it on after i opened the packaging. the colors were not as vibrant as the picture. as another reviewer mentioned, it was more similar to something you would purchase off a boardwalk. very disappointed and will be returning.                                             |[0.04527347756315548,0.08206482214718624,0.8726617002896583]|2.0       |\n","|If you are going for a ridiculously high priced ugly sweater contest, this is the one for you. i normally like clothing with some character and juxtaposition, but this one did not do it for me. i cannot imagine the collar fitting right or flattering anyone, and the mixed layers end up making it look cheap rather than trendy.                                                                                                                          |[0.1348569535829008,0.14267716250740808,0.722465883909691]  |2.0       |\n","|I saw this online and immediately purchased the top in gray. it's so easy and casual but the shoulder detailing give it something different and unique for a regular gray shirt. the fit is loose and comfortable but not overly big, just right. i can't wait to pair it with my new white jeans for summer!                                                                                                                                                   |[0.8305356137761847,0.11013183542318754,0.0593325508006278] |0.0       |\n","+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------+----------+\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"M1QIubPzPa7u"},"source":["## Lưu và Tải model"]},{"cell_type":"code","metadata":{"id":"4cJpnxOrRoMa"},"source":["lg_model_2.save('/content/gdrive/MyDrive/LDS9_K269_ONLINE_NgoThiNga/LDS9_K269_NgoThiNga_Cuoi_ky/Cau1_model')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NEEHnezFRYnI"},"source":["from pyspark.ml import PipelineModel\n","lg_model_load = PipelineModel.load('Cau1_model')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lO55Bz8GVSZh"},"source":[""],"execution_count":null,"outputs":[]}]}